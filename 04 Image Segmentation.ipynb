{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>031 Segmentation and Contours</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/312.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/31.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/311.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contours</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/313.png')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#finding Contours\n",
    "# Use a copy your image, eg. edge.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Numper of Contours found = \" + str(len(contours)))\n",
    "print(contours)\n",
    "# Drow all contours \n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/314.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/315.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/316.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/317.png')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#finding Contours\n",
    "# Use a copy your image, eg. edge.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Numper of Contours found = \" + str(len(contours)))\n",
    "print(contours)\n",
    "# Drow all contours \n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/317.png')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#finding Contours\n",
    "# Use a copy your image, eg. edge.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Numper of Contours found = \" + str(len(contours)))\n",
    "print(contours)\n",
    "# Drow all contours \n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>032 Sorting Contours</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/320.png')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Create a black image with same dimenstions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "#Create a copy of our original image\n",
    "original_image = image\n",
    "\n",
    "#Grayscale our image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny image\n",
    "edged =  cv2.Canny(image, 50, 200)\n",
    "cv2.imshow('1- Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print('Numper of contours found = ', len(contours))\n",
    "\n",
    "#Draw all contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow('2- All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Draw all contours over blank image\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow('3- All Contours', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's now sort contours by area size</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/320.png')\n",
    "orginal_image = image \n",
    "\n",
    "# Function we'll use to display contour area\n",
    "def get_contour_areas(contours):\n",
    "    # returns the areas of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "#Grayscale our image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny image\n",
    "edged =  cv2.Canny(image, 50, 200)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Print contours area before sorting \n",
    "print \"Contor Areas before sorting\",\n",
    "print get_contour_areas(contours)\n",
    "\n",
    "#sort contours large to small\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "\n",
    "print \"Contor Areas after sorting\",\n",
    "print get_contour_areas(sorted_contours)\n",
    "\n",
    "# Iterate over our contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(orginal_image, [c], -1, (0, 255,0), 3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by area', orginal_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sorting contours from left to right </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "image = cv2.imread('images/ct0.JPG')\n",
    "orginal_image = image.copy() \n",
    "\n",
    "# Function we'll use for sorting by position\n",
    "def x_cord_contour(contours):\n",
    "    #Returns the X cordinate for the contour centroid\n",
    "    if cv2.contourArea(contours)>10:\n",
    "        M = cv2.moments(contours)\n",
    "        if (M['m00']) == 0 : M['m00'] = .01\n",
    "        return(int(M['m10']/M['m00']))\n",
    "\n",
    "def label_contour_center(image, c):\n",
    "    #Places a red circle on the centers of contours\n",
    "    M = cv2.moments(c)\n",
    "    if (M['m00']) == 0 : M['m00'] = .01\n",
    "    cx= int(M['m10']/M['m00'])\n",
    "    cy= int(M['m01']/M['m00'])\n",
    "    \n",
    "    #Draw the contour number on the image\n",
    "    cv2.circle(image, (cx, cy), 10, (0,0,255), -1)\n",
    "    return image\n",
    "\n",
    "#Grayscale our image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny image\n",
    "edged =  cv2.Canny(image, 50, 200)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# computer Center of Mass or centroid and draw them on out image\n",
    "for (i, c) in enumerate(contours):\n",
    "    orig = label_contour_center(image, c)\n",
    "\n",
    "cv2.imshow('4- contour Center', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort by left to right using our x_cord_contour function\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "#labling contours left to right \n",
    "for(i,c) in enumerate(contours_left_to_right):\n",
    "    #cv2.drawContours(orginal_image, [c], -1, (0,0,255), 3)\n",
    "    cv2.drawContours(image, [c], -1, (0,0,255), 3)\n",
    "    M = cv2.moments(c)\n",
    "    if (M['m00']) == 0 : M['m00'] = .01\n",
    "    cx= int(M['m10']/M['m00'])\n",
    "    cy= int(M['m01']/M['m00'])\n",
    "    #cv2.putText(orginal_image, str(i+1), (cx-5,cy-5), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 255, 0), 2)\n",
    "    cv2.putText(image, str(i+1), (cx-5,cy-5), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 255, 0), 2)\n",
    "    #cv2.imshow('6- left to right contour ', orginal_image)\n",
    "    cv2.imshow('6- left to right contour ', image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    #Let's now crop each contour and save these images\n",
    "    cropped_contour = orginal_image[y:y+h, x:x+w]\n",
    "    image_name = \"images/32-contours/output_shape_number_\" + str(i+1) + \".jpg\"\n",
    "    #print image_name\n",
    "    cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>033 Approximating Contours and Finding their Convex Hull</h1>\n",
    "<img src=\"images/33.png\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "\n",
    "#### 033 Approximating Contours and finding their convex hull\n",
    "### cv2.approxPolyDP(input_contour, approximation accuracy, closed)\n",
    "#### approximation accuracy - small value gives precise approximations, large values give more generi approximation\n",
    "### a good rule of thumb is less than 5% for the contour perimeter\n",
    "### Closed - a Boolean value that states whether the approximate contour should be open or closed\n",
    "#########################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "## Load image and keep a copy\n",
    "image = cv2.imread('images/330.png')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Grayscale and binarize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "### Find Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "### Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    cv2.imshow('Bounding Rectangle', orig_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "### Iterate through each contour and compute the approx. contour\n",
    "for c in contours:\n",
    "    ### Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.01 * cv2.arcLength(c, True)  ### play with the decimal for accuracy\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)  ### This is how we approximate contours\n",
    "    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "image = cv2.imread('images/hand.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "### Find Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "## Sort contours by area and then remove the largest frame contour\n",
    "n = len(contours) - 1  ### For white background, the whole are is taken as the first biggest contour\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse = False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "image = cv2.imread('images/hand.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "### Find Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "## Sort contours by area and then remove the largest frame contour\n",
    "n = len(contours) #- 1  ### For white background, the whole are is taken as the first biggest contour\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse = False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>034 Matching Contour Shapes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128017921378\n",
      "0.159151548991\n",
      "9.49729968894e-05\n",
      "0.00694147887054\n",
      "0.0433692019441\n",
      "0.0629582364336\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "\n",
    "#### Shape Matching\n",
    "### cv2.matchShape(contour template, contour, method, method parameter)\n",
    "### contour template is the reference contour that we are trying to find in the new image\n",
    "### contour - the indivcidual contour we are checking against\n",
    "### method = type of contour matching (1, 2, 3)\n",
    "### method parameter - leave alone as 0.0 (not fully utilized in python opencv)\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "### Load the shape template or reference image\n",
    "template = cv2.imread('images/4star.jpg', 0) ### 0 at the end loads the image as grayscale\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey()\n",
    "\n",
    "### Load the traget image with the shapes we are trying to match\n",
    "target = cv2.imread('images/shapestomatch.jpg')\n",
    "target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "### Threshold both images first before using cv2.findContours\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "### Find contours in template\n",
    "#ret, contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "### We need to sort the contours by area so that we can remove the largest contour which is the image outline\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "## We extract the second largest contour which will be our template contour\n",
    "template_contour = contours[1]\n",
    "\n",
    "## Extract contours from second target image\n",
    "#ret, contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "closest_contour = []\n",
    "for c in contours:\n",
    "    ## Iterate through each contour in the target image and \n",
    "    ###  use cv2.matchShape to compare contour shapes\n",
    "    match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "    print(match)\n",
    "    cv2.waitKey()\n",
    "    ## if the match value is less than 0.15 we \n",
    "    if match < 0.05:\n",
    "        closest_contour.append(c)\n",
    "\n",
    "cv2.drawContours(target, closest_contour, -1, (0, 255, 0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>035 Mini Project  2 - Identifying Shapes</h1>\n",
    "<img src=\"images/350.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "### Load the image\n",
    "image = cv2.imread('images/someshapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Identifying shapes', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "## Extract Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    ### get approximate polygons\n",
    "    approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), True)\n",
    "    \n",
    "    if len(approx) == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "        cv2.drawContours(image, [cnt], 0, (0,255,0), -1)\n",
    "        \n",
    "        ## Find Contour center to place text at the center\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "    elif len(approx) == 4:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        ### Check to see if 4-side polygon is square or rectangel\n",
    "        ### cv2.boundingRect returns the top left and then width and \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = 'Square'\n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125, 255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "            \n",
    "        else:\n",
    "            shape_name = 'Rectangle'\n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 0, 255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "            \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = 'Star'\n",
    "        cv2.drawContours(image, [cnt], 0, (255, 255, 0), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "    elif len(approx) >= 15:\n",
    "        shape_name = 'Circle'\n",
    "        cv2.drawContours(image, [cnt], 0, (0, 255, 255), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "    cv2.imshow('Identifying Shapes', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>036 Line Detection</h1>\n",
    "<img src=\"images/360.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#### Line detection - Hough lines and probabilistic Hough lines  \n",
    "#### Imagine being used in lane detection in self driving cars, in chess boards\n",
    "####   ro = x cos theta + y sin theta , where ro is the perpendicular distance from the origin and\n",
    "####               theta is the angle formed by the normal of this line to the origin (in radians)\n",
    "#### cv2.HoughLines(binarized image, ro accuracy, theta accuracy, threshold)\n",
    "###                 threshold here is the minimum vote for it to be considered a line\n",
    "###probabilistic Hough lines - idea is that it takes only a random subset of points sufficient enough for line detection\n",
    "#### also returns the start and end point of the line unlike the previous function\n",
    "\n",
    "#### cv2.HoughLinesP(binarized image, ro accuracy, theta accurancy, threshold, minimum line length, max line gap)\n",
    "###    http://www.bmva.org/bmvc/1998/pdf/p176.pdf\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/kerenal.jpg')\n",
    "\n",
    "# Grayscale and canny edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)  ## canny edges help a bit in transforms\n",
    "\n",
    "### Run Houghlines using a rho accuracy of 1 pixel\n",
    "### theta accuracy of np.pi/180 which is 1 degree\n",
    "### our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "### We iterate through each line and convert it to the format required by cv.lines (i.e., requiring end points)\n",
    "for rho, theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 68L, 4L)\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "\n",
    "#### Probabilistic Hough Lines\n",
    "#### cv2.HoughLinesP(binarized image, ro accuracy, theta accurancy, threshold, minimum line length, max line gap)\n",
    "###    http://www.bmva.org/bmvc/1998/pdf/p176.pdf\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "### Grayscale and canny Edges extracted\n",
    "image = cv2.imread('images/kerenal.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "### Again we use the same rho and theta accuracies\n",
    "### However, we specify a minimum vote(points along line) of 100\n",
    "### and min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 200, 5, 10)\n",
    "print(lines.shape)\n",
    "\n",
    "for x1, y1, x2, y2 in lines[0]:\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Probabilistic Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h1>037 Circle Detection</h1>\n",
    "    <h2>Circle Detection with Hough Cirlces</h2>\n",
    "    <h3>cv2.HoughCircles(image, method, dp, MinDist, param1, param2, minRadius, MaxRadius)</h3>\n",
    "    <img src=\"images/bottlecap.JPG\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "    <ul><li><strong class=\"redactor-inline-converted\">Method&nbsp;</strong>-&nbsp;currently only cv2.HOUGH_GRADIENT available</li><li><strong class=\"redactor-inline-converted\">dp&nbsp;</strong>-&nbsp;Inverse ratio of accumulator resolution</li><li><strong class=\"redactor-inline-converted\">MinDist&nbsp;</strong>-&nbsp;the minimum distance between the center of detected circles</li><li><strong class=\"redactor-inline-converted\">param1&nbsp;</strong>-&nbsp;Gradient value used in the edge detection</li><li><strong class=\"redactor-inline-converted\">param2&nbsp;</strong>-&nbsp;Accumulator threshold for the HOUGH_GRADIENT method, lower allows more circles to be detected (false positives)</li><li><strong class=\"redactor-inline-converted\">minRadius&nbsp;</strong>-&nbsp;limits the smallest circle to this size (via radius)</li><li><strong>MaxRadius&nbsp;</strong>-&nbsp;similarly sets the limit for the largest circles</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.cv as cv\n",
    "\n",
    "image = cv2.imread('images/bottlecap1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "circles = cv2.HoughCircles(blur, cv.CV_HOUGH_GRADIENT, 1.5, 10)\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "      \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>038 Blob Detection</h1>\n",
    "<img src=\"images/380.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/381.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/380.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Set up the detector with default parameters\n",
    "detector = cv2.SimpleBlobDetector()\n",
    "\n",
    "# Draw blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0, 255, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "#Show keypoints\n",
    "cv2.imshow('blobs', blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>039 Mini Project  3 - Counting Circles and Ellipses</h1>\n",
    "<img src=\"images/390.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">\n",
    "<img src=\"images/393.jpg\" style=\"display: block; margin: 10px auto; max-width:97%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/391.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('Orginal Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Set up the detector with default parameters\n",
    "detector = cv2.SimpleBlobDetector()\n",
    "\n",
    "# Draw blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "number_of_blobs = len(keypoints)\n",
    "text = \"Total Number of Blobs:\" + str(len(keypoints))\n",
    "cv2.putText(blobs, text, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 0, 255), 2)\n",
    "\n",
    "#Display image with blob keypoints\n",
    "cv2.imshow('Blobs using default parameters', blobs)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#set our filtering parameters\n",
    "# Initialize parameter setting using cv2.SimpleBlobDetector\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "#set Area filtering parameters\n",
    "params.filterByArea = True\n",
    "params.minArea = 100\n",
    "\n",
    "#set our filtering parameters\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.9\n",
    "\n",
    "# Ser Convexity filtering parameters\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.2\n",
    "\n",
    "# Set Inertia filtering parameters\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "detector = cv2.SimpleBlobDetector(params)\n",
    "\n",
    "# Detect blobs\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "number_of_blobs = len(keypoints)\n",
    "text = \"Number of Circular Blobs:\" + str(len(keypoints))\n",
    "cv2.putText(blobs, text, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 255), 2)\n",
    "\n",
    "\n",
    "#Show keypoints\n",
    "cv2.imshow('Filtering Circular Blobs Only', blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
